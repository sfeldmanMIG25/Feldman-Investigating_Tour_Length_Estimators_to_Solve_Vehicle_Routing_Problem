# xml_large_sol_generator.py
"""
Generates and prices VRP solutions using multiple heuristics, saving them
to separate folders for comparison.

This script uses a parallel process pool to process instances efficiently.
"""
import os
import sys
import time
import math
import subprocess
import numpy as np
from pathlib import Path
from tqdm import tqdm
from itertools import combinations
import collections
import concurrent.futures
from ortools.constraint_solver import routing_enums_pb2, pywrapcp
#import vroom


# --- Ensure required files can be imported ---
SCRIPT_DIR = Path(__file__).parent
DATA_DIR = SCRIPT_DIR.parent
sys.path.append(str(SCRIPT_DIR))

try:
    from vrp_utils import (
        parse_vrp,
        solve_tsp_lkh,
        get_true_VRP_cost,
        get_true_heuristic_cost,
        generate_initial_solution_k_means,
        balance_by_node_movement,
    )
    from initial_solution_generator import generate_feasible_solution_regret
except ImportError as e:
    print(f"FATAL: Could not import a required module. Error: {e}")
    sys.exit(1)

# --- Configuration ---
OUTPUT_BASE_DIR = DATA_DIR
INSTANCES_DIR_MEDIUM = DATA_DIR / "instances_medium"
INSTANCES_DIR_LARGE = DATA_DIR / "instances_large"

# --- Common Helper Functions ---

def get_minimum_vehicles(total_demand, capacity):
    """Calculates the minimum number of vehicles required to satisfy demand."""
    return math.ceil(total_demand / capacity)

def write_solution_file(
    filepath,
    routes,
    cost,
    time_taken,
    algo_name
):
    """Writes a solution file in the standard CVRPLIB format with time taken appended."""
    with open(filepath, 'w') as f:
        f.write(f"VRP solution generated by {algo_name}\n")
        f.write(f"Cost: {cost}\n")
        # Corrected loop to iterate over the dictionary's values (the routes themselves)
        for i, route in enumerate(routes.values()):
            f.write(f"Route #{i+1}: {' '.join(map(str, route))}\n")
        f.write(f"Time: {time_taken}\n")
        f.write("EOF\n")

# --- Heuristic Implementations ---

def solve_clark_wright(customer_data, depot_id, depot_coord, capacity):
    """Implements the Clark-Wright savings algorithm."""
    customer_ids = list(customer_data.keys())
    routes = {cid: [cid] for cid in customer_ids}
    route_demands = {cid: customer_data[cid]['demand'] for cid in customer_ids}
    
    savings = []
    coords = {**{depot_id: depot_coord}, **{cid: data['coords'] for cid, data in customer_data.items()}}
    
    for i, j in combinations(customer_ids, 2):
        s_ij = np.linalg.norm(np.array(coords[depot_id]) - np.array(coords[i])) + \
               np.linalg.norm(np.array(coords[depot_id]) - np.array(coords[j])) - \
               np.linalg.norm(np.array(coords[i]) - np.array(coords[j]))
        savings.append((s_ij, i, j))
    
    savings.sort(key=lambda x: x[0], reverse=True)
    
    endpoints = {cid: (cid, cid) for cid in customer_ids}
    
    for _, i, j in savings:
        route_i_id = next((k for k, v in routes.items() if i in v), None)
        route_j_id = next((k for k, v in routes.items() if j in v), None)
        
        if route_i_id and route_j_id and route_i_id != route_j_id:
            i_is_start_of_i = (endpoints[route_i_id][0] == i)
            i_is_end_of_i = (endpoints[route_i_id][1] == i)
            j_is_start_of_j = (endpoints[route_j_id][0] == j)
            j_is_end_of_j = (endpoints[route_j_id][1] == j)
            
            if not (i_is_start_of_i or i_is_end_of_i): continue
            if not (j_is_start_of_j or j_is_end_of_j): continue
            
            new_demand = route_demands[route_i_id] + route_demands[route_j_id]
            if new_demand <= capacity:
                route_i = routes[route_i_id]
                route_j = routes[route_j_id]
                new_route = None
                
                if i_is_end_of_i and j_is_start_of_j:
                    new_route = route_i + route_j
                elif i_is_start_of_i and j_is_end_of_j:
                    new_route = route_j + route_i
                elif i_is_end_of_i and j_is_end_of_j:
                    new_route = route_i + route_j[::-1]
                elif i_is_start_of_i and j_is_start_of_j:
                    new_route = route_i[::-1] + route_j

                if new_route:
                    routes[route_i_id] = new_route
                    route_demands[route_i_id] = new_demand
                    new_start = new_route[0]
                    new_end = new_route[-1]
                    endpoints[route_i_id] = (new_start, new_end)
                    del routes[route_j_id]
                    del endpoints[route_j_id]

    final_partition = {i: route for i, route in enumerate(routes.values())}
    return final_partition

def solve_nearest_neighbor(customer_data, depot_id, depot_coord, capacity):
    """
    Implements a greedy Nearest Neighbor heuristic to build routes.
    """
    unassigned_nodes = set(customer_data.keys())
    routes = collections.defaultdict(list)
    route_idx = 0
    
    coords = {**{depot_id: depot_coord}, **{cid: data['coords'] for cid, data in customer_data.items()}}
    
    while unassigned_nodes:
        current_route_demand = 0
        current_node = depot_id
        
        while True:
            closest_neighbor = None
            min_dist = float('inf')
            
            for neighbor in unassigned_nodes:
                demand = customer_data[neighbor]['demand']
                if current_route_demand + demand <= capacity:
                    dist = np.linalg.norm(np.array(coords[current_node]) - np.array(coords[neighbor]))
                    if dist < min_dist:
                        min_dist = dist
                        closest_neighbor = neighbor
            
            if closest_neighbor is None:
                break
            
            routes[route_idx].append(closest_neighbor)
            current_route_demand += customer_data[closest_neighbor]['demand']
            current_node = closest_neighbor
            unassigned_nodes.remove(closest_neighbor)
        
        route_idx += 1
    
    final_partition = {i: route for i, route in routes.items() if route}
    return final_partition

def solve_or_tools(customer_data, depot_id, depot_coord, capacity, num_vehicles):
    """
    Solves the VRP using Google's OR-Tools library.
    """
    all_node_ids = sorted(list(customer_data.keys()) + [depot_id])
    id_to_index = {node_id: i for i, node_id in enumerate(all_node_ids)}
    index_to_id = {i: node_id for i, node_id in enumerate(all_node_ids)}
    
    coords = {**{depot_id: depot_coord}, **{cid: data['coords'] for cid, data in customer_data.items()}}
    
    dist_matrix = [[int(np.linalg.norm(np.array(coords[index_to_id[i]]) - np.array(coords[index_to_id[j]]))) for j in range(len(all_node_ids))] for i in range(len(all_node_ids))]
    
    manager = pywrapcp.RoutingIndexManager(len(all_node_ids), num_vehicles, id_to_index[depot_id])
    routing = pywrapcp.RoutingModel(manager)
    
    def distance_callback(from_index, to_index):
        return dist_matrix[manager.IndexToNode(from_index)][manager.IndexToNode(to_index)]
    
    transit_callback_index = routing.RegisterTransitCallback(distance_callback)
    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)
    
    demands_list = [customer_data[index_to_id[i]]['demand'] if index_to_id[i] in customer_data else 0 for i in range(len(all_node_ids))]
    def demand_callback(from_index):
        return demands_list[manager.IndexToNode(from_index)]
        
    demand_callback_index = routing.RegisterUnaryTransitCallback(demand_callback)
    routing.AddDimensionWithVehicleCapacity(
        demand_callback_index,
        0,
        [capacity] * num_vehicles,
        True,
        'Capacity'
    )
    
    search_parameters = pywrapcp.DefaultRoutingSearchParameters()
    search_parameters.first_solution_strategy = (routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)
    
    solution = routing.SolveWithParameters(search_parameters)
    
    if solution:
        routes = collections.defaultdict(list)
        for vehicle_id in range(num_vehicles):
            index = routing.Start(vehicle_id)
            while not routing.IsEnd(index):
                node_index = manager.IndexToNode(index)
                if node_index != id_to_index[depot_id]:
                    routes[vehicle_id].append(index_to_id[node_index])
                index = solution.Value(routing.NextVar(index))
        return routes
    else:
        return {}

# --- Main Analysis Function ---

def process_instance(instance_path, solver_name):
    """
    Processes a single instance using a specified solver and prices the solution.
    Designed for parallel execution.
    """
    try:
        start_time = time.perf_counter()
        capacity, depot_id, coords, demands = parse_vrp(instance_path)
        depot_coord = coords[depot_id]
        customer_data = {
            nid: {'coords': c, 'demand': demands.get(nid, 0)}
            for nid, c in coords.items() if nid != depot_id
        }
        all_customer_data_orig = {
            nid: {'coords': coords[nid], 'demand': demands.get(nid, 0)}
            for nid in coords
        }
        
        total_demand = sum(demands.values())
        num_vehicles = math.ceil(total_demand / capacity)
        
        solution = {}
        if solver_name == 'ClarkWright':
            solution = solve_clark_wright(customer_data, depot_id, depot_coord, capacity)
        elif solver_name == 'KMeans':
            k_means_solution = generate_initial_solution_k_means(customer_data, num_vehicles, capacity)
            solution = balance_by_node_movement(k_means_solution, customer_data, capacity)
        elif solver_name == 'NearestNeighbor':
            solution = solve_nearest_neighbor(customer_data, depot_id, depot_coord, capacity)
        elif solver_name == 'OrTools':
            solution = solve_or_tools(customer_data, depot_id, depot_coord, capacity, num_vehicles)
        elif solver_name == 'Vroom':
            solution = solve_vroom(customer_data, depot_id, depot_coord, capacity, num_vehicles)
            
        final_time = time.perf_counter() - start_time
        
        if not solution:
            raise RuntimeError("Failed to generate a valid solution.")

        # Correct for OR-Tools output format
        final_solution = {k: v for k, v in solution.items() if v}
        
        total_cost = get_true_VRP_cost(final_solution, all_customer_data_orig, depot_id)

        return {
            'instance_path': instance_path,
            'solver_name': solver_name,
            'solution': final_solution,
            'cost': total_cost,
            'time_taken': final_time,
        }
    except Exception as e:
        print(f"Error processing {instance_path.name} with {solver_name}: {e}")
        return None
    
# --- New Heuristic Implementation for Vroom ---

def solve_vroom(customer_data, depot_id, depot_coord, capacity, num_vehicles):
    """
    Solves the VRP using the vroom Python library by building an Input object.
    Avoids NumPy objects in the distance matrix to prevent 'Incompatible buffer format!' errors.
    """

    # Create the problem instance
    vroom_problem = vroom.Input()

    # Build a list of all node coordinates (customers + depot)
    all_node_ids = sorted(list(customer_data.keys()) + [depot_id])
    id_to_index = {node_id: i for i, node_id in enumerate(all_node_ids)}
    index_to_id = {i: node_id for i, node_id in enumerate(all_node_ids)}

    # Merge depot and customer coordinates into one dict
    coords = {**{depot_id: depot_coord},
              **{cid: data['coords'] for cid, data in customer_data.items()}}

    # Build a pure-Python distance matrix (Euclidean, floored to int)
    dist_matrix = []
    for i in range(len(all_node_ids)):
        row = []
        xi, yi = coords[index_to_id[i]]
        for j in range(len(all_node_ids)):
            xj, yj = coords[index_to_id[j]]
            dist = math.hypot(xi - xj, yi - yj)  # float
            row.append(int(dist))  # ensure native Python int
        dist_matrix.append(row)

    # Add the distance matrix with the required profile
    vroom_problem.set_durations_matrix(
        profile="car",
        matrix_input=dist_matrix
    )

    # Add jobs (customers)
    for cid in customer_data:
        vroom_problem.add_job(
            vroom.Job(
                id=cid,
                location_index=id_to_index[cid],
                delivery=[int(customer_data[cid]['demand'])]
            )
        )

    # Add vehicles
    for vid in range(num_vehicles):
        vroom_problem.add_vehicle(
            vroom.Vehicle(
                id=vid,
                start=id_to_index[depot_id],
                end=id_to_index[depot_id],
                capacity=[int(capacity)]
            )
        )

    # Solve the problem
    solution = vroom_problem.solve()

    if solution.routes:
        routes = collections.defaultdict(list)
        for route in solution.routes:
            routes[route.vehicle_id] = [
                step.job.id for step in route.steps if step.job
            ]
        return dict(routes)
    else:
        return {}
    
def main():
    """Main function to orchestrate the solution generation."""
    
    solvers1 = ['ClarkWright', 'KMeans', 'NearestNeighbor', 'OrTools']
    
    # Process medium instances
    for solver_name in solvers1:
        output_dir = OUTPUT_BASE_DIR / f"solutions_medium_{solver_name.lower()}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        all_instances = list(INSTANCES_DIR_MEDIUM.glob('XML*.vrp'))
        total_instances = len(all_instances)
        
        if not total_instances: continue
        
        num_workers = os.cpu_count() or 1
        with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:
            futures = {executor.submit(process_instance, path, solver_name): path for path in all_instances}
            for future in tqdm(concurrent.futures.as_completed(futures), total=total_instances, desc=f"Generating {solver_name} Solutions (Medium)"):
                result = future.result()
                if result:
                    sol_filepath = output_dir / f"{result['instance_path'].stem}.sol"
                    write_solution_file(sol_filepath, result['solution'], result['cost'], result['time_taken'], result['solver_name'])

    # Process large instances
    solvers2 = ['KMeans', 'NearestNeighbor', 'OrTools']
    for solver_name in solvers2:
        output_dir = OUTPUT_BASE_DIR / f"solutions_large_{solver_name.lower()}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        all_instances = list(INSTANCES_DIR_LARGE.glob('XML*.vrp'))
        total_instances = len(all_instances)
        
        if not total_instances: continue
        
        num_workers = os.cpu_count() or 1
        with concurrent.futures.ProcessPoolExecutor(max_workers=num_workers) as executor:
            futures = {executor.submit(process_instance, path, solver_name): path for path in all_instances}
            for future in tqdm(concurrent.futures.as_completed(futures), total=total_instances, desc=f"Generating {solver_name} Solutions (Large)"):
                result = future.result()
                if result:
                    sol_filepath = output_dir / f"{result['instance_path'].stem}.sol"
                    write_solution_file(sol_filepath, result['solution'], result['cost'], result['time_taken'], result['solver_name'])

    print("\nSolution generation complete.")

def mainMemReduce():
    solvers=['OrTools']
    for solver_name in solvers:
        output_dir = OUTPUT_BASE_DIR / f"solutions_large_{solver_name.lower()}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        all_instances = list(INSTANCES_DIR_LARGE.glob('XML*.vrp'))
        total_instances = len(all_instances)
        
        if not total_instances: continue
        print(f"Generating {solver_name} Solutions (Large) Sequentially...")
        for instance_path in tqdm(all_instances, total=total_instances, desc=f"Generating {solver_name} Solutions (Large)"):
            result = process_instance(instance_path,solver_name)
            if result:
                sol_filepath = output_dir / f"{result['instance_path'].stem}.sol"
                write_solution_file(sol_filepath, result['solution'], result['cost'], result['time_taken'], result['solver_name'])

def mainVroom():
    """
    Main function to orchestrate the solution generation for Vroom.
    This runs sequentially to preserve computer memory.
    """
    solver_name = 'Vroom'
    
    # Process medium instances sequentially
    output_dir_medium = OUTPUT_BASE_DIR / f"solutions_medium_{solver_name.lower()}"
    output_dir_medium.mkdir(parents=True, exist_ok=True)
    
    all_instances_medium = list(INSTANCES_DIR_MEDIUM.glob('XML*.vrp'))
    total_instances_medium = len(all_instances_medium)
    
    if total_instances_medium:
        print(f"Generating {solver_name} Solutions (Medium) Sequentially...")
        for instance_path in tqdm(all_instances_medium, total=total_instances_medium, desc=f"Processing {solver_name} (Medium)"):
            result = process_instance(instance_path, solver_name)
            if result:
                sol_filepath = output_dir_medium / f"{result['instance_path'].stem}.sol"
                write_solution_file(sol_filepath, result['solution'], result['cost'], result['time_taken'], result['solver_name'])

    # Process large instances sequentially
    output_dir_large = OUTPUT_BASE_DIR / f"solutions_large_{solver_name.lower()}"
    output_dir_large.mkdir(parents=True, exist_ok=True)
    
    all_instances_large = list(INSTANCES_DIR_LARGE.glob('XML*.vrp'))
    total_instances_large = len(all_instances_large)
    
    if total_instances_large:
        print(f"Generating {solver_name} Solutions (Large) Sequentially...")
        for instance_path in tqdm(all_instances_large, total=total_instances_large, desc=f"Processing {solver_name} (Large)"):
            result = process_instance(instance_path, solver_name)
            if result:
                sol_filepath = output_dir_large / f"{result['instance_path'].stem}.sol"
                write_solution_file(sol_filepath, result['solution'], result['cost'], result['time_taken'], result['solver_name'])

    print(f"\nSolution generation for {solver_name} complete.")

if __name__ == '__main__':
    mainVroom()